<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: linux | Keen on Art of Tech]]></title>
  <link href="http://tinyxd.me/tags/linux/atom.xml" rel="self"/>
  <link href="http://tinyxd.me/"/>
  <updated>2012-07-30T18:48:31+08:00</updated>
  <id>http://tinyxd.me/</id>
  <author>
    <name><![CDATA[Tiny]]></name>
    <email><![CDATA[admin@tinyxd.me]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[linux内存管理（上）]]></title>
    <link href="http://tinyxd.me/blog/2012/07/29/linux-memory-management-1/"/>
    <updated>2012-07-29T23:33:00+08:00</updated>
    <id>http://tinyxd.me/blog/2012/07/29/linux-memory-management-1</id>
    <content type="html"><![CDATA[<p><strong><em>摘要</em></strong>：内核如何给自己分配动态内存呢？</p>

<p>“页框管理”和“内存区管理”是对连续物理内存区处理的两种不同技术。</p>

<p>“非连续内存区管理”是处理非连续内存区的第三种技术。</p>

<h2>页框管理  </h2>

<p>intel的Pentium处理器可以采用两种不同的页框大小：4KB和4MB。Linux采用4KB页框大小作为标准的内存分配单元。物理页在系统中由页框结构struct paga描述，系统中所有的页框存储在数组mem_map[]中，可以通过该数组找到系统中的每一页（空闲或非空闲）。</p>

<!--more-->


<h2>内存管理区  </h2>

<p>Linux2.6把每个内存节点的物理内存划分为3个管理区（zone）。在80X86UMA体系结构中的管理区为：</p>

<p>ZONE_DMA：包含低于16MB的内存页框</p>

<p>ZONE_NORMAL：包含高于16MB且低于896MB的内存页框</p>

<p>ZONE_HIGHMEM：包含从896MB开始高于896MB的内存页框（并不映射在内核线性地址空间的第4个GB）</p>

<p>注意：ZONE_DMA和ZONE_NORMAL区包含内存的“常规”页框，通过把它们线性映射到线性地址空间的第4个GB，内核就可以直接进行访问。相反，ZONE_HIGHMEM区包含的内存页不能由内核直接访问，尽管它们也线性地映射到了线性地址空间的第4个GB。在64位体系结构上ZONE_HIGHMEM区总是空的。</p>

<p>Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数4k(在i386体系结构中)大小页，从而分配和回收内存的基本单位便是内存页了。利用分页管理有助于灵活分配内存地址，因为分配时不必要求必须有大块的连续内存，系统可以东一页、西一页的凑出所需要的内存供进程使用。虽然如此，但是实际上系统使用内存还是倾向于分配连续的内存块，因为分配连续内存时，页表不需要更改，因此能降低TLB的刷新率（频繁刷新会很大增加访问速度）。</p>

<p>鉴于上述需求，内核分配物理页为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页框。伙伴关系分配算法大家不应陌生——几乎所有操作系统书都会提到,我们不去详细说它了，如果不明白可以参看有关资料。这里只需要大家明白Linux中空闲页面的组织和管理利用了伙伴关系，因此空闲页面分配时也需要遵循伙伴关系，最小单位只能是2的幂倍页面大小。内核中分配空闲页框的基本函数是get_free_page/get_free_pages，它们或是分配单页或是分配指定的页框（2、4、8…512页）。</p>

<p>注意：get_free_page是在内核中分配内存，不同于malloc在用户空间中分配，malloc利用堆动态分配，实际上是调用brk()系统调用，该调用的作用是扩大或缩小进程堆空间（它会修改进程的brk域）。如果现有的内存区域不够容纳堆空间，则会以页面大小的倍数位单位，扩张或收缩对应的内存区域，但brk值并非以页面大小为倍数修改，而是按实际请求修改。因此Malloc在用户空间分配内存可以以字节为单位分配,但内核在内部仍然会是以页为单位分配的。</p>

<h2>高端内存页框的内核映射  </h2>

<p>内核可以采用三种不同的机制将页框映射到高端内存；分别叫做永久内核映射、临时内核映射及非连续内存分配。</p>

<p>永久内核映射可能阻塞当前进程，不能用于中断处理程序和可延迟函数。</p>

<p>临时内核映射比永久内核映射的实现要简单，可以用在中断处理程序和可延迟函数的内部，因为它们从不阻塞当前进程。</p>

<h2>伙伴系统算法（buddy systerm）  </h2>

<p>内核要分配一组连续的页框，必须建立一种健壮、高效的分配策略。为此，必须解决著名的外部碎片（external fragmentation）问题。频繁地请求和释放不同大小的一组连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页框。由此带来的问题是，即使有足够的空闲页框可以满足请求，但要分配一个大块的连续页框就可能无法满足。</p>

<p>Linux 采用伙伴系统（buddy system）算法来解决外碎片问题。把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1, 2, 4, 8, 16, 32, 64, 128, 256，512和1024 个连续的页框。对1024 个页框的最大请求对应着4MB 大小的连续RAM块。每个块的第一个页框的物理地址是该块大小的整数倍。例如，大小为16 个页框的块，其起始地址是16 × 212（212 ＝ 4096，这是一个常规页的大小）的倍数。</p>

<p>本文章参考自《深入理解linux内核》及 <a href="http://www.cnblogs.com/hoys/archive/2011/09/08/2171606.html">Linux内存管理(上)</a> 。 <br/>
本站文章如果没有特别说明，均为<strong>原创</strong>，转载请以<strong>链接</strong>方式注明本文地址：<a href="http://tinyxd.me/blog/2012/07/29/linux-memory-management-1/">http://tinyxd.me/blog/2012/07/29/linux-memory-management-1/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux进程调度]]></title>
    <link href="http://tinyxd.me/blog/2012/07/26/linux-process-scheduling/"/>
    <updated>2012-07-26T23:18:00+08:00</updated>
    <id>http://tinyxd.me/blog/2012/07/26/linux-process-scheduling</id>
    <content type="html"><![CDATA[<p><strong><em>摘要</em></strong>：linux与任何分时系统一样，通过一个进程到另一个进程的快速切换，达到表面上看来的多个进程同时执行的神奇效果。</p>

<br />


<p>Linux的调度基于分时（time sharing）技术：多个进程以“时间多路复用”方式运行，因为CPU的时间被分成“片（slice）”，给每个可运行进程分配一片。</p>

<p>在linux中，进程的优先级是动态的。调度程序跟踪进程正在做什么，并周期性地调整它们的优先级。</p>

<h2>分类 </h2>

<p>传统上，把进程分类为“IO受限（IO bound）”或“CPU受限（CPU bound）”。前者频繁使用IO设备，并花费很多时间等待IO操作的完成；而后者则需要大量CPU时间的数值计算应用程序。</p>

<p>另一种分类方法把进程区分为三类：交互式进程（interactive process）、批处理进程（batch process、实时进程（real-time process）。</p>

<!--more-->


<p></p>

<h2>进程的抢占 </h2>

<p>Linux的进程是抢占式的。根据优先级和时间片是否国企决定是否可以被抢占。</p>

<p>Linux2.6内核是抢占式的，这意味着进程无论是处于内核态还是用户态，都可能被抢占。</p>

<h2>调度算法 </h2>

<p>调度程序总能成功地找到要执行的进程。事实上，总是至少有一个可运行进程，即swapper进程，它的PID等于0，而且它只有在CPU不能执行其他进程时才执行。</p>

<p>每个Linux进程总是按照下面的调度类型被调度：</p>

<p>SCHED_FIFO（先进先出的实时进程）：直到先被执行的进程变为非可执行状态，后来的进程才被调度执行。在这种策略下，先来的进程可以执行sched_yield系统调用，自愿放弃CPU，以让权给后来的进程；</p>

<p>SCHED_RR（时间片轮转的实时进程）：轮转调度。内核为实时进程分配时间片，在时间片用完时，让下一个进程使用CPU；</p>

<p>SCHED_NORMAL（普通的分时进程）。</p>

<h2>普通进程的调度 (参考自<a href="http://hi.baidu.com/_kouu/blog/item/52471ab5e90e7c788ad4b24a.html">linux进程调度浅析</a>) </h2>

<p>实时进程调度的中心思想是，让处于可执行状态的最高优先级的实时进程尽可能地占有CPU，因为它有实时需求；而普通进程则被认为是没有实时需求的进程，于是调度程序力图让各个处于可执行状态的普通进程和平共处地分享CPU，从而让用户觉得这些进程是同时运行的。</p>

<p>每个普通进程都有它自己的静态优先级，还有动态优先级。</p>

<p>与实时进程相比，普通进程的调度要复杂得多。内核需要考虑两件麻烦事：</p>

<p>一、动态调整进程的优先级</p>

<p>按进程的行为特征，可以将进程分为“交互式进程”和“批处理进程”：</p>

<p>交互式进程（如桌面程序、服务器、等）主要的任务是与外界交互。这样的进程应该具有较高的优先级，它们总是睡眠等待外界的输入。而在输入到来，内核将其唤醒时，它们又应该很快被调度执行，以做出响应。比如一个桌面程序，如果鼠标点击后半秒种还没反应，用户就会感觉系统“卡”了；</p>

<p>批处理进程（如编译程序）主要的任务是做持续的运算，因而它们会持续处于可执行状态。这样的进程一般不需要高优先级，比如编译程序多运行了几秒种，用户多半不会太在意；</p>

<p>如果用户能够明确知道进程应该有怎样的优先级，可以通过nice、setpriority系统调用来对优先级进行设置。（如果要提高进程的优先级，要求用户进程具有CAP_SYS_NICE能力。）</p>

<p>然而应用程序未必就像桌面程序、编译程序这样典型。程序的行为可能五花八门，可能一会儿像交互式进程，一会儿又像批处理进程。以致于用户难以给它设置一个合适的优先级。</p>

<p>再者，即使用户明确知道一个进程是交互式还是批处理，也多半碍于权限或因为偷懒而不去设置进程的优先级。（你又是否为某个程序设置过优先级呢？）</p>

<p>于是，最终，区分交互式进程和批处理进程的重任就落到了内核的调度程序上。</p>

<p>调度程序关注进程近一段时间内的表现（主要是检查其睡眠时间和运行时间），根据一些经验性的公式，判断它现在是交互式的还是批处理的？程度如何？最后决定给它的优先级做一定的调整。</p>

<p>进程的优先级被动态调整后，就出现了两个优先级：</p>

<p>1、用户程序设置的优先级（如果未设置，则使用默认值），称为静态优先级。这是进程优先级的基准，在进程执行的过程中往往是不改变的；</p>

<p>2、优先级动态调整后，实际生效的优先级。这个值是可能时时刻刻都在变化的；</p>

<p>二、调度的公平性</p>

<p>在支持多进程的系统中，理想情况下，各个进程应该是根据其优先级公平地占有CPU。而不会出现“谁运气好谁占得多”这样的不可控的情况。</p>

<p>linux实现公平调度基本上是两种思路：</p>

<p>1、给处于可执行状态的进程分配时间片（按照优先级），用完时间片的进程被放到“过期队列”中。等可执行状态的进程都过期了，再重新分配时间片；</p>

<p>2、动态调整进程的优先级。随着进程在CPU上运行，其优先级被不断调低，以便其他优先级较低的进程得到运行机会；</p>

<p>后一种方式有更小的调度粒度，并且将“公平性”与“动态调整优先级”两件事情合而为一，大大简化了内核调度程序的代码。因此，这种方式也成为内核调度程序的新宠。</p>

<p>强调一下，以上两点都是仅针对普通进程的。而对于实时进程，内核既不能自作多情地去动态调整优先级，也没有什么公平性可言。</p>

<p>普通进程具体的调度算法非常复杂，并且随linux内核版本的演变也在不断更替（不仅仅是简单的调整），所以本文就不继续深入了。有兴趣的朋友可以参考下面的链接：</p>

<p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-scheduler/">《Linux 调度器发展简述》</a></p>

<p><a href="http://blog.chinaunix.net/u1/42957/showart.php?id=337597">《鼠眼看Linux调度器》</a></p>

<p><a href="http://blog.chinaunix.net/u1/42957/showart.php?id=337604">《鼠眼再看Linux调度器［1］》</a></p>

<p><a href="http://blog.chinaunix.net/u1/42957/showart.php?id=337607">《鼠眼再看Linux调度器［2］》</a></p>

<h2>实时进程的调度 </h2>

<p>每个实时进程都与一个实时优先级相关，实时优先级是一个范围从1（最高优先级）~99（最低优先级）的值。调度程序总是让优先级高的进程运行，换句话说，实时进程运行的过程中，禁止低优先级的进程的执行。与普通进程相反，实时进程总是被当成活动进程。用户可以通过系统调用sched_setparam()和sched_setscheduler()改变进程的实时优先级。</p>

<p>只有在下述时间之一发生时，实时进程才会被另一个进程取代：</p>

<pre><code>进程被另外一个具有更高实时优先级的实时进程抢占 

进程执行了阻塞操作并进入睡眠（处于TASK_INTERRUPTIBLE或TASK_UNINTERRUPTIBLE状态）。 

进程停止（处于TASK_STOPPED或TASK_TRACED状态）或被杀死（处于EXIT_ZOMBIE或EXIT_DEAD状态）。 

进程通过调用系统调用sched_yield()自愿放弃CPU。 

进程是基于时间片轮转的实时进程（SCHED_RR），而且用完了它的时间片。 
</code></pre>

<p>数据结构runqueue是Linux2.6调度程序最重要的数据结构。系统中的每个CPU都有它自己的运行队列，所有的runqueue结构存放在runqueues每CPU变量中。</p>

<h2>调度程序所使用的函数 </h2>

<p>scheduler_tick()：维持当前最新的time_slice计数器</p>

<p>try_to_wake_up()：唤醒睡眠进程</p>

<p>recalc_task_prio()：更新进程的动态优先级</p>

<p>schedule()：选择要被执行的新进程</p>

<p>load_balance()：维持多处理器系统中运行队列的平衡</p>

<h2>多处理器系统中运行队列的平衡 </h2>

<p>Linux一直坚持采用对称多处理模式，这意味着，与其他CPU相比，内核不对一个CPU有任何偏向，但是，多处理器机器具有很多不同的风格，而且调度程序的实现随硬件特征的不同而有所不同，我们将特别关注下面三种不同类型的多处理器机器：</p>

<p>（1）标准的多处理器体系结构</p>

<p>直到最近，这是多处理器机器最普通的体系结构。这些机器所共有的RAM芯片集被所有CPU共享。</p>

<p>（2）超线程</p>

<p>超线程芯片是一个立刻执行几个执行线程的微处理器；它包括几个内部寄存器的拷贝，并快速在它们之间切换。这种由Intel发明的技术，使得当前线程在访问内存的间隙，处理器可以使用它的机器周期去执行另外一个线程。一个超线程的物理CPU可以被Linux看作几个不同的逻辑CPU。</p>

<p>（3）NUMA</p>

<p>把CPU和RAM以本地“结点”为单位分组，（通常一个结点包括一个CPU和几个RAM芯片）。内存仲裁器（一个使系统中的CPU以串型方式访问RAM的专用电路）是典型的多处理器系统的瓶颈。在NUMA体系结构中，当CPU访问与它同在一个结点中的“本地”RAM芯片时，几乎没有竞争，因此访问通常是非常快的。另一方面，访问它所属结点外的“远程”RAM芯片就非常慢。</p>

<h2>与调度相关的系统调用 </h2>

<p>nice()、getpriority()和setpriority()系统调用、sched_getaffinity()和sched_setaffinity()调用</p>

<h2>与实时进程相关的系统调用 </h2>

<p>sched_getscheduler()和sched_setscheduler()系统调用、sched_getparam()和sched_setparam()系统调用、sched_yield()系统调用、sched_get_priority_min()和 sched_get_priority_max()系统调用、sched_rr_get_interval()系统调用</p>

<br />


<p>本文章参考自《深入理解linux内核》。 <br/>
本站文章如果没有特别说明，均为<strong>原创</strong>，转载请以<strong>链接</strong>方式注明本文地址：<a href="http://tinyxd.me/blog/2012/07/26/linux-process-scheduling/">http://tinyxd.me/blog/2012/07/26/linux-process-scheduling/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux系统定时测量]]></title>
    <link href="http://tinyxd.me/blog/2012/07/26/linux-timing-measurements/"/>
    <updated>2012-07-26T12:48:00+08:00</updated>
    <id>http://tinyxd.me/blog/2012/07/26/linux-timing-measurements</id>
    <content type="html"><![CDATA[<p>Linux内核必须完成的两种主要定时测量：</p>

<p>保存当前的时间和日期，以便通过time()、ftime()、gettimeofday()系统调用把它们返回给用户程序，也可以由内核本身把当前时间作为文件和网络包的时间戳。</p>

<p>维持定时器，这种机制能够告诉内核或用户程序某一时间间隔已经过去了。</p>

<p>一般会遇到的几种时钟和定时器电路：实时时钟（Real Time Clock RTC）、时间戳计数器（Time Stamp Counter TSC）、可编程间隔定时器（Programmable Interval Timer PIT）、CPU本地定时器（APIC中）、高精度事件定时器（HPET）、ACPI电源管理定时器。</p>

<p>Linux的计时体系结构是一组与时间流相关的内核数据结构和函数。实际上，基于80x86多处理器机器所具有的计时体系结构与单处理器机器所具有的稍有不同：</p>

<p>在三处理器系统上，所有的计时活动都是由全局定时器（可以是可编程间隔定时器也可以是高精度事件定时器）产生的中断触发的。</p>

<!--more-->


<p>在多处理器系统上，所有普通的活动（像软定时器处理）都是由全局定时器产生的中断触发的，而具体的CPU的活动（像监控当前运行进程的执行时间）是由本地APIC定时器产生的中断触发的。</p>

<p>jiffies</p>

<p>jiffies是一个计数器，用来记录自系统启动依赖产生的节拍总数。启动时，内核将该变量初始化为0，此后，每次时钟中断处理程序都会增加该变量的值。因为一秒内时钟中断的次数等于Hz，所以jiffies一秒内增加的值也就为Hz。系统运行时间以秒为单位计算，就等于jiffies/Hz。</p>

<p>xtime</p>

<p>xtime变量存放当前时间和日期；它是一个timespec类型的数据结构，该结构有两个字段：</p>

<p>1.tv_sec 存放自1970年1月1日（UTC）午夜以来经过的秒数。</p>

<p>2.tv_nsec存放自上一秒开始经过的纳秒数（它的值域范围在0-999999999之间）</p>

<p>在单处理器系统上，所有与定时有关的活动都是由IRQ线0上的可编程间隔定时器产生的中断触发的。</p>

<p>多处理器系统可以依赖两种不同的时钟中断源：可编程间隔定时器或高精度事件定时器产生的中断，以及CPU本地定时器产生的中断(监管内核代码并检测当前进程在特定CPU上已经运行了多长时间)。</p>

<p>内核在于定时相关的其他任务中必须周期性地收集若干数据用于：</p>

<pre><code>检查运行进程的CPU资源限制  

更新与本地CPU工作负载有关的统计数  

计算平均系统负载  

监管内核代码  
</code></pre>

<p>软定时器和延迟函数</p>

<p>定时器是一种软件功能，即允许在将来的某个时期，函数在给定的时间间隔用完时被调用。超时（time-out）表示与定时器相关的时间间隔已经用完的那个时刻。</p>

<p>Linux考虑两种类型的定时器，即动态定时器（dynamic timer）和间隔定时器（interval timer）。第一种类型由内核使用，而间隔定时器可以由进程在用户态创建。</p>

<p>延迟函数</p>

<p>当内核需要等待一个较短的时间间隔（比方说，不超过几毫秒）时，就不需要使用软定时器。</p>

<p>开发驱动，需要较短的时间间隔，在以上情况下，内核使用udelay()和ndelay()函数：前者接收一个微妙级的时间间隔作为它的参数，并在指定的延迟结束后返回；后者与前者类似，但是指定的延迟参数是纳秒级的。</p>

<p>本文章参考自《深入理解linux内核》。 <br/>
本站文章如果没有特别说明，均为<strong>原创</strong>，转载请以<strong>链接</strong>方式注明本文地址：<a href="http://tinyxd.me/blog/2012/07/26/linux-timing-measurements/">http://tinyxd.me/blog/2012/07/26/linux-timing-measurements/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[archlinux升级出现关于glibc的问题解决办法]]></title>
    <link href="http://tinyxd.me/blog/2012/07/25/archlinux-update-about-glibc/"/>
    <updated>2012-07-25T18:44:00+08:00</updated>
    <id>http://tinyxd.me/blog/2012/07/25/archlinux-update-about-glibc</id>
    <content type="html"><![CDATA[<p>好久没更新archlinux，今天更新，发现由于archlinux系统根目录结构的改变，导致好多人遇到问题，不错，笔者必然也遇到了。由于有前人的探索，再加上查阅archlinux官网论坛，得以顺利解决问题。
运行<code>pacman -Syu</code>时会出现 <br/>
<code>
error: failed to commit transaction (conflicting files)
glibc: /lib exists in filesystem
Errors occurred, no packages were upgraded.
</code> <br/>
由于这次是glibc的升级，绝对不可以用<code>--force</code>，而之前是filesysterm的升级，必须用<code>--force</code>。 <br/>
那么接下来该怎么办呢？ <br/>
查阅了archlinux论坛地址：<a href="https://bbs.archlinux.org/viewforum.php?id=44">https://bbs.archlinux.org/viewforum.php?id=44</a>，并参考了<a href="http://www.j927.net/arch/archlinux%E5%8D%87%E7%BA%A7%E5%A4%B1%E8%B4%A5%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E8%AE%B0%E5%BD%95.html">这篇文章</a>。    <br/>
发现这个<a href="https://bbs.archlinux.org/viewtopic.php?id=145186">帖子</a>，其中提到这两篇文章：<a href="http://allanmcrae.com/2012/07/updating-arch-linux-from-a-core-install/">updating-arch-linux-from-a-core-install</a> 和<a href="https://wiki.archlinux.org/index.php/DeveloperWiki:usrlib">DeveloperWiki:usrlib</a>，总结以下命令：</p>

<!--more-->


<p> <br/>
<code>
shell &gt; pacman -Sy
shell &gt; rm -rf /var/run /var/lock &amp;&amp; pacman -Sf filesystem
shell &gt; pacman -S tzdata
shell &gt; pacman -U http://pkgbuild.com/~allan/glibc-2.16.0-1-i686.pkg.tar.xz #32位的用这个包(和下面的一条命令二选一)
shell &gt; pacman -U http://pkgbuild.com/~allan/glibc-2.16.0-1-x86_64.pkg.tar.xz #64位的用这个包 具体的包名称可以打开http://pkgbuild.com/~allan/看一下
shell &gt; rm /etc/profile.d/locale.sh
shell &gt; pacman -Su --ignore glibc #因为pacman也升级了，新版本开启了软件包签名验证，故还需要运行下面2条命令
shell &gt; pacman-key --init #该命令运行后不要什么都不做，随机敲键盘或者切换到其它终端(Alt+F2)运行些命令或做些其它操作
shell &gt; pacman-key --populate archlinux
shell &gt; pacman -Su #再更新被忽略的glibc
</code>
执行完上述命令后，系统顺利更新好了，但是依然出现下述问题： <br/>
<code>
error: failed to commit transaction (conflicting files)
glibc: /lib exists in filesystem
Errors occurred, no packages were upgraded.
</code> <br/>
我就去论坛中寻找，果不其然也有类似于我的情况，原帖<a href="http://bbs.archbang.org/viewtopic.php?pid=16509">在此</a>。
<code>
shell &gt; pacman -R broadcom-wl
shell &gt; pacman -Su
shell &gt; pacman -S broadcom-wl #如果需要的话，再次安装即可
</code>
至此，升级结束。</p>

<br />


<p>本站文章如果没有特别说明，均为<strong>原创</strong>，转载请以<strong>链接</strong>方式注明本文地址：<a href="http://tinyxd.me/blog/2012/07/25/archlinux-update-about-glibc/">http://tinyxd.me/blog/2012/07/25/archlinux-update-about-glibc/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux内核同步]]></title>
    <link href="http://tinyxd.me/blog/2012/07/18/linux-kernel-synchronization/"/>
    <updated>2012-07-18T15:57:00+08:00</updated>
    <id>http://tinyxd.me/blog/2012/07/18/linux-kernel-synchronization</id>
    <content type="html"><![CDATA[<h2>内核抢占</h2>

<p>抢占内核的主要特点是：一个在内核态运行的进程，可能在执行内核函数期间被另外一个进程取代。 <br/>
只有当内核正在执行异常处理程序（尤其是系统调用），而且内核抢占没有被显式地禁用时，才可能抢占内核。 <br/>
内核使用的各种同步技术：每CPU变量、原子操作、内存屏障、自旋锁、信号量、顺序锁、本地中断的禁止、本地软中断的禁止、读-拷贝-更新（RCU）。</p>

<h2>每CPU变量</h2>

<p>主要是数据结构的数组，系统的每个CPU对应数组的一个元素。 <br/>
一个CPU不应该访问与其他CPU对应的数组元素。另外，它可以随意读或修改它自己的元素而不用担心出现竞争条件，因为它是唯一有资格这么做的CPU。在单处理器和多处理器系统中，内核抢占都可能使每CPU变量产生竞争条件。总的原则是内核控制路径应该在禁用抢占的情况下访问每CPU变量。</p>

<!--more-->


<h2>原子操作</h2>

<p>若干汇编语言指令具有“读-修改-写”类型----也就是说，它们访问存储器单元两次，第一次读原值，第二次写新值。 <br/>
Linux内核提供了一个专门的atomic_t类型（一个原子计数器）和一些专门的函数和宏。在多处理器系统中，每条这样的指令都有一个lock字节（“锁定内存总线，直到这条指令执行完成”）的前缀。</p>

<h2>优化和内存屏障</h2>

<p>当使用优化的编译器时，编译器为了优化可能会重新安排汇编语言指令以便寄存器以最优的方式使用。 <br/>
内存屏障（memory barrier）原语确保，在原语之后的操作开始执行之前，原语之前的操作已经完成。</p>

<h2>自旋锁</h2>

<p>自旋锁（spin lock）是用来在多处理器环境中工作的一种特殊的锁。如果内核控制路径发现自旋锁“开着”，就获取锁并继续自己的执行。相反，如果内核控制路径发现锁由运行在另一个CPU上的内核控制路径“锁着”，就在周围“旋转”。反复执行一条紧凑的循环指令，直到锁被释放。   <br/>
一般来说，由自旋锁所保护的每个临界区都是禁止内核抢占的。在单处理器系统上，这种锁本身并不起锁的作用，自旋锁原语仅仅是禁止或启用内核抢占。  <br/>
在linux中，每个自旋锁都用spinlock_t结构表示，其中包含两个字段：</p>

<p>1.slock----表示自旋锁的状态。（1--未加锁  负数和0--加锁） <br/>
2.break_lock----表示进程正在忙等自旋锁（只在内核支持SMP和内核抢占的情况下使用该标志）</p>

<p>读写自旋锁的引入是为了增加内核的并发能力。只要没有内核控制路径堆数据结构进行修改，读写自旋锁就允许多个内核控制路径读同一数据结构。允许对数据结构并发度可以提高系统性能。 <br/>
顺序锁：与读写自旋锁非常相似，只是它为写者赋予了较高的优先级；事实上，即使在读者正在读的时候也允许写者继续运行。这种策略的好处是写者永远不会等待（除非另外一个写者正在写），缺点是有些时候读者不得不反复多次读相同的数据直到获得有效的副本。 <br/>
当读者进入临界区时，不必禁用内核抢占；另一方面，由于写者获取自旋锁，所以它进入临界区时自动禁用内核抢占。 <br/>
一般来说，在满足以下条件时才能使用顺序锁：</p>

<p>1.被保护的数据结构不包括被写者修改和被读者间接引用的指针（否则，写者可能在读者的眼鼻下就修改指针）。 <br/>
2.读者的临界区代码没有副作用（否则，多个读者的操作会与单独的读操作有不同的结果）。</p>

<h2>读-拷贝-更新（RCU）</h2>

<p>读-拷贝-更新（RCU）是为了保护在多数情况下被多个CPU读的数据结构而设计的另一种同步技术。RCU允许多个读者和写者并发执行，RCU不使用锁，就是说它不使用被所有CPU共享的锁或计数器。  <br/>
RCU同步的关键思想是：</p>

<p>1.RCU只保护被动态分配并通过指针引用的数据结构。 <br/>
2.在被RCU保护的临界区中，任何内核控制路径都不能睡眠。</p>

<p>使用RCU技术的真正困难在于：写者修改指针时不能立即释放数据结构的旧副本。实际上，写着开始修改时，正在访问数据结构的读者可能还在读旧副本。只有在CPU上的所有（潜在的）读者都执行完宏rcu_read_unlock()之后，才可以释放旧副本。 <br/>
RCU是Linux2.6中新加的功能，用在网络层和虚拟文件系统中。</p>

<h2>信号量</h2>

<p>Linux提供两种信号量：</p>

<p>1.内核信号量，由内核控制路径使用 <br/>
2.Systerm V IPC 信号量，由用户态进程使用</p>

<p>内核信号量：类似于自旋锁，因为当锁关闭着时，它不允许内核控制路径继续进行。只有可以睡眠的函数才能获取内核信号量；中断处理程序和可延迟函数都不能使用内核控制量。 <br/>
内核信号量是struct semaphore类型的对象。 <br/>
TASK_INTERRUPTIBLE是可以被信号和wake_up()唤醒的，当信号到来时，进程会被设置为可运行。 <br/>
而TASK_UNINTERRUPTIBLE只能被wake_up()唤醒。 <br/>
读/写信号量：类似于前面的“读写自旋锁”，有一点不同的是，在信号量再次变为打开之前，等待进程挂起而不是自旋。内核以严格的FIFO顺序处理等待读写信号量的所有进程。 <br/>
每个读写信号量都是有rw_semaphore结构描述的。 <br/>
补充原语（completion）：其和信号量之间的真正区别在于如何使用等待队列中包含的自旋锁。在补充原语中，自旋锁用来确保complete()和wait_for_completion()不会并发执行。在信号量中，自旋锁用于避免并发执行的down()函数弄乱信号量的数据结构。</p>

<br />


<p>本文章参考自《深入理解linux内核》。 <br/>
本站文章如果没有特别说明，均为<strong>原创</strong>，转载请以<strong>链接</strong>方式注明本文地址：<a href="http://tinyxd.me/blog/2012/07/18/linux-kernel-synchronization/">http://tinyxd.me/blog/2012/07/18/linux-kernel-synchronization/</a></p>
]]></content>
  </entry>
  
</feed>
